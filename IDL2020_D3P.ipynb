{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IDL2020_D3P.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YTe1C5XDclhf","colab_type":"text"},"source":["This notebook illustrates the use of convolutional networks for a multiclass classification over the MNIST dataset. This notebook is based on the PyTorch MNIST example: https://github.com/pytorch/examples/tree/master/mnist\n","\n","The MNIST dataset contains handwritten digits like these:\n","\n"," ![MNIST samples](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n","\n","Each digit is 28x28 pixels and is labeled with the digit it contains, e.g. this is labeled with a \"0\":\n","\n","<img src=\"http://neuralnetworksanddeeplearning.com/images/mnist_complete_zero.png\" width=\"200\">\n"]},{"cell_type":"code","metadata":{"id":"ypFnkACT2Iam","colab_type":"code","outputId":"55607743-d561-402a-a894-3561d0edf63a","executionInfo":{"status":"ok","timestamp":1579172095016,"user_tz":-60,"elapsed":14633,"user":{"displayName":"Noé Casas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDGlw-X22xGNGqJghtCZLMeavg1ImQz7_NVNHcf7g=s64","userId":"07955841278825489857"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["!pip install pillow==5.4.1\n","!pip install matplotlib\n","!pip install scikit-learn\n","!pip install torch\n","!pip install torchvision"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pillow==5.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 3.5MB/s \n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: pillow\n","  Found existing installation: Pillow 6.2.2\n","    Uninstalling Pillow-6.2.2:\n","      Successfully uninstalled Pillow-6.2.2\n","Successfully installed pillow-5.4.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n","Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kMd_kEOr2NvZ","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AnLzYv47HSN","colab_type":"code","colab":{}},"source":["seed = 20\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(seed)\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzndZca2JgSO","colab_type":"text"},"source":["Let's define our model. The standard PyTorch way of doing so is to create a class inheriting from `torch.nn.Module`.\n","\n","In its `__init__` method, we create the layers we are going to need and store them as member variables.\n","\n","In its `forward` method we implement the forward pass computation, making use of the layers we created in the constructor."]},{"cell_type":"code","metadata":{"id":"s5DkDQTg2SdP","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(4*4*50, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = x.view(-1, 4*4*50)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLWyr0RpJ9Tj","colab_type":"text"},"source":["Now let's create a function that trains over an epoch. Every N steps we will `print` the progress. As input to the training, we are going to assume we receive an iterator to the training batches.\n","\n","Note that, as we are facing a multiclass classification problem, we use the **negative log likelihood** (NLL) as loss function."]},{"cell_type":"code","metadata":{"id":"8lVf4Ae52pde","colab_type":"code","colab":{}},"source":["def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    losses = []\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.item())\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","    return losses"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fj-oQ2erKaXz","colab_type":"text"},"source":["And now let's create a similar function but to evaluate the performance of the model over a validation data set:"]},{"cell_type":"code","metadata":{"id":"LLnHRErC2wEv","colab_type":"code","colab":{}},"source":["def validate(model, device, loader):\n","    \n","    model.eval()  # let's put the model in evaluation mode\n","\n","    validation_loss = 0\n","    correct = 0\n","    \n","    with torch.no_grad():  # we don't need gradient computation at all\n","        for data, target in loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            validation_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    validation_loss /= len(loader.dataset)\n","\n","    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        validation_loss, correct, len(loader.dataset),\n","        100. * correct / len(loader.dataset)))\n","    \n","    return validation_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XeDtTK_LR2B","colab_type":"text"},"source":["Now, we will use the dataset from `torchvision` to load MNIST and the PyTorch loaders to get iterators to the batches, for both training and validation data.\n","\n","Note that we apply a linear transformation to normalize the data."]},{"cell_type":"code","metadata":{"id":"rDkgOWa12zJ5","colab_type":"code","outputId":"c5434409-414c-4f5b-d3cb-86efb2b8fdb5","executionInfo":{"status":"ok","timestamp":1579172096579,"user_tz":-60,"elapsed":16095,"user":{"displayName":"Noé Casas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDGlw-X22xGNGqJghtCZLMeavg1ImQz7_NVNHcf7g=s64","userId":"07955841278825489857"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["train_batch_size = 128\n","\n","mnist_mean = 0.1307\n","mnist_stddev = 0.3081\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data',\n","                   train=True,\n","                   download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((mnist_mean,), (mnist_stddev,))\n","                   ])),\n","    batch_size=train_batch_size,\n","    shuffle=True)\n","\n","valid_batch_size = 1000\n","valid_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data',\n","                   train=False,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((mnist_mean,), (mnist_stddev,))\n","                   ])),\n","    batch_size=valid_batch_size,\n","    shuffle=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["  0%|          | 16384/9912422 [00:00<01:28, 111585.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:00, 22797143.77it/s]                           \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 304218.57it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 5462369.66it/s]                           \n","8192it [00:00, 131990.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Shp-xfiCMtBe","colab_type":"text"},"source":["And finally, let's create the network, move it to the GPU and iterate through some epochs of training:"]},{"cell_type":"code","metadata":{"id":"cXyU5Joa4Ekh","colab_type":"code","outputId":"488cdbad-08f3-4a4e-dbe9-b2eab65e08c3","executionInfo":{"status":"ok","timestamp":1579172212540,"user_tz":-60,"elapsed":132046,"user":{"displayName":"Noé Casas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDGlw-X22xGNGqJghtCZLMeavg1ImQz7_NVNHcf7g=s64","userId":"07955841278825489857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n","\n","train_losses = []\n","valid_losses = []\n","valid_x = []\n","num_epochs = 10\n","for epoch in range(1, num_epochs + 1):\n","    epoch_losses = train(80, model, device, train_loader, optimizer, epoch)\n","    train_losses.extend(epoch_losses)\n","    valid_loss = validate(model, device, valid_loader)\n","    valid_losses.append([valid_loss])\n","    valid_x.append(len(train_losses) - 1)\n","\n","plt.gcf().clear()\n","plt.plot(train_losses, 'b-')\n","plt.plot(valid_x, valid_losses, 'r-')\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311603\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.663087\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.339903\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.232071\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.246467\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.124858\n","\n","Validation set: Average loss: 0.1658, Accuracy: 9497/10000 (95%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.160722\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.263896\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.111822\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.124030\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.136134\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.117874\n","\n","Validation set: Average loss: 0.0959, Accuracy: 9709/10000 (97%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.088699\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.073224\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.135686\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.046536\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.047021\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.069571\n","\n","Validation set: Average loss: 0.0696, Accuracy: 9791/10000 (98%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.081784\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.067662\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.074869\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.044988\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.020337\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.042134\n","\n","Validation set: Average loss: 0.0557, Accuracy: 9820/10000 (98%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.062998\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.046947\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.093039\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.026674\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.038007\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.062348\n","\n","Validation set: Average loss: 0.0482, Accuracy: 9846/10000 (98%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.035051\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.031152\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.053704\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.078318\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.038933\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.097376\n","\n","Validation set: Average loss: 0.0521, Accuracy: 9823/10000 (98%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.036793\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.046687\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.028834\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.027746\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.076784\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.010591\n","\n","Validation set: Average loss: 0.0442, Accuracy: 9850/10000 (98%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.009639\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.021358\n","Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.044594\n","Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.008712\n","Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.008969\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.050698\n","\n","Validation set: Average loss: 0.0409, Accuracy: 9867/10000 (99%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.028924\n","Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.030430\n","Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.039208\n","Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.008220\n","Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.044199\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.043435\n","\n","Validation set: Average loss: 0.0373, Accuracy: 9876/10000 (99%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.064809\n","Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.007611\n","Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.025615\n","Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.024516\n","Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.007511\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006730\n","\n","Validation set: Average loss: 0.0345, Accuracy: 9874/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEAwoBMRFYj/B1g8REixjCwVAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}